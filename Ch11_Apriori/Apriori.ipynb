{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Apriori \n",
        "\n",
        "通过查看哪些商品经常在一起购买，可以帮助商店了解用户的购买行为。这种从数据海洋中 抽取的知识可以用于商品定价、市场促销、存货管理等环节。从大规模数据集中寻找物品间的隐 含关系被称作关联分析（association analysis）或者关联规则学习（association rule learning）。这 里的主要问题在于，寻找物品的不同组合是一项十分耗时的任务，所需的计算代价很高，蛮力搜 索方法并不能解决这个问题，所以需要用更智能的方法在合理的时间范围内找到频繁项集。本章 将介绍如何使用Apriori算法来解决上述问题。\n",
        "\n",
        "下面首先详细讨论关联分析，然后讨论Apriori原理，Apriori算法正是基于该原理得到的。接下来创建函数频繁项集高效发现的函数，然后从频繁项集中抽取出关联规则。本章最后给出两个 例子，一个是从国会投票记录中抽取出关联规则，另一个是发现毒蘑菇的共同特征。\n",
        "\n",
        "优点：易编码实现。缺点：在大数据集上可能较慢。适用数据类型：数值型或者标称型数据。\n",
        "\n",
        "关联分析是一种在大规模数据集中寻找有趣关系的任务。这些关系可以有两种形式：频繁项 集或者关联规则。 频繁项集（frequent item sets）是经常出现在一块的物品的集合， 关联规则 （association rules）暗示两种物品之间可能存在很强的关系。下面会用一个例子来说明这两种概 念。\n",
        "\n",
        "频繁项集是指那些经常出现在一起的物品集合，图11-1中的集合{葡萄酒，尿布, 豆奶}就是频 繁项集的一个例子（回想一下，集合是由一对大括号“{ }”来表示的）。从下面的数据集中也可 以找到诸如尿布 ➞葡萄酒的关联规则。这意味着如果有人买了尿布，那么他很可能也会买葡萄酒。 使用频繁项集和关联规则，商家可以更好地理解他们的顾客。尽管大部分关联规则分析的实例来 自零售业，但该技术同样可以用于其他行业，比如网站流量分析以及医药行业。\n",
        "\n",
        "一个项集的支持度（support）被定义为数据集中包含该项集的记录所占的比例。从图11-1中 可以得到，{豆奶}的支持度为4/5。而在5条交易记录中有3条包含{豆奶，尿布}，因此{豆奶，尿 布}的支持度为3/5。支持度是针对项集来说的，因此可以定义一个最小支持度，而只保留满足最 小支持度的项集。\n",
        "\n",
        "可信度或置信度（confidence）是针对一条诸如{尿布} ➞ {葡萄酒}的关联规则来定义的。这条规则的可信度被定义为“支持度({尿布, 葡萄酒})/支持度({尿布})”。从图11-1中可以看到，由 于{尿布, 葡萄酒}的支持度为3/5，尿布的支持度为4/5，所以“尿布 ➞ 葡萄酒”的可信度为3/4=0.75。 这意味着对于包含“尿布”的所有记录，我们的规则对其中75%的记录都适用。\n",
        "\n",
        "支持度和可信度是用来量化关联分析是否成功的方法。假设想找到支持度大于0.8的所有项集，应该如何去做？一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出 现的频繁程度，但当物品成千上万时，上述做法非常非常慢。下一节会详细分析这种情况并讨论 Apriori原理，该原理会减少关联规则学习时所需的计算量。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apriori 原理\n",
        "\n",
        "假设我们在经营一家商品种类并不多的杂货店，我们对那些经常在一起被购买的商品非常感兴 趣。我们只有4种商品：商品0，商品1，商品2和商品3。那么所有可能被一起购买的商品组合都有 哪些？这些商品组合可能只有一种商品，比如商品0，也可能包括两种、三种或者所有四种商品。 我们并不关心某人买了两件商品0以及四件商品2的情况，我们只关心他购买了一种或多种商品。\n",
        "\n",
        "图11-2显示了物品之间所有可能的组合。为了让该图更容易懂，图中使用物品的编号0来取 代物品0本身。另外，图中从上往下的第一个集合是  ，表示空集或不包含任何物品的集合。物 品集合之间的连线表明两个或者更多集合可以组合形成一个更大的集合。\n",
        "\n",
        "前面说过，我们的目标是找到经常在一起购买的物品集合。而在11.1节中，我们使用集合的 支持度来度量其出现的频率。一个集合的支持度是指有多少比例的交易记录包含该集合。如何对 一个给定的集合，比如{0,3}，来计算其支持度？我们遍历每条记录并检查该记录包含0和3，如 果记录确实同时包含这两项，那么就增加总计数值。在扫描完所有数据之后，使用统计得到的总数除以总的交易记录数，就可以得到支持度。上述过程和结果只是针对单个集合{0,3}。要获得 每种可能集合的支持度就需要多次重复上述过程。我们可以数一下图11-2中的集合数目，会发现 即使对于仅有4种物品的集合，也需要遍历数据15次。而随着物品数目的增加遍历次数会急剧增长。对于包含N种物品的数据集共有$2^N -1$种项集组合。事实上，出售10 000或更多种物品的商店 并不少见。即使只出售100种商品的商店也会有$1.26×10^{30}$ 种可能的项集组合。对于现代的计算机 而言，需要很长的时间才能完成运算。\n",
        "\n",
        "<img src=\"pic/pic.png\" style=\"width:400;height:400px;\">"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了降低所需的计算时间，研究人员发现一种所谓的Apriori原理。Apriori原理可以帮我们减 少可能感兴趣的项集。Apriori原理是说如果某个项集是频繁的，那么它的所有子集也是频繁的。 对于图11-2给出的例子，这意味着如果{0,1}是频繁的，那么{0}、{1}也一定是频繁的。这个原理 直观上并没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是非频繁集，那么 它的所有超集也是非频繁的（如图11-3所示）。\n",
        "\n",
        "在图11-3中， 已知阴影项集{2,3}是非频繁的。 利用这个知识， 我们就知道项集{0,2,3}， {1,2,3}以及{0,1,2,3}也是非频繁的。这也就是说， 一旦计算出了{2,3}的支持度， 知道它是非 频繁的之后， 就不需要再计算{0,2,3}、{1,2,3}和{0,1,2,3}的支持度， 因为我们知道这些集合 不会满足我们的要求。 使用该原理就可以避免项集数目的指数增长， 从而在合理时间内计算 出频繁项集。\n",
        "\n",
        "<img src=\"pic/pic1.png\" style=\"width:400;height:400px;\">\n",
        "\n",
        "图中给出了所有可能的项集，其中非频繁项集用灰色表示。由于集合{2,3}是非频繁的， 因此{0,2,3}、{1,2,3}和{0,1,2,3}也是非频繁的，它们的支持度根本不需要计算"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用 Apriori 算法来发现频繁集\n",
        "\n",
        "11.1节提到，关联分析的目标包括两项：发现频繁项集和发现关联规则。首先需要找到频繁 项集，然后才能获得关联规则。本节将只关注于发现频繁项集。 Apriori算法是发现频繁项集的一种方法。Apriori算法的两个输入参数分别是最小支持度和数 据集。该算法首先会生成所有**单个物品的项集列表**。接着扫描交易记录来查看哪些项集满足最小 支持度要求，那些不满足最小支持度的集合会被去掉。然后，对剩下来的集合进行**组合以生成包含两个元素的项集**。接下来，再重新扫描交易记录，去掉不满足最小支持度的项集。该过程重复进行直到所有项集都被去掉。\n",
        "\n",
        "#### 生成候选项集\n",
        "\n",
        "创建一个通过扫描数据集以寻找交易记录子集的函数。数据集扫描的伪代码 大致如下：\n",
        "\n",
        "    对数据集中的每条交易记录tran \n",
        "    对每个候选项集can：\n",
        "        检查一下can是否是tran的子集： \n",
        "            如果是，则增加can的计数值\n",
        "    对每个候选项集： \n",
        "    如果其支持度不低于最小值，则保留该项集 (作为频繁集)\n",
        "    返回所有频繁项集列表\n",
        "    \n",
        "函数createC1()将构建集合C1。C1是只有一个元素的所有候选项集的集合。Apriori 算法首先构建集合C1，\n",
        "然后扫描数据集来判断这些只有一个元素的项集是否满足最小支持度的要求。那些满足最低要求的项集构成集合L1。\n",
        "而L1中的元素相互组合构成C2，C2再进一步过滤变为L2。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import apriori\n",
        "dataSet = apriori.loadDataSet()\n",
        "dataSet"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#构建第一个候选项集集合C1：C1包含了每个frozenset中的单个物品项\n",
        "C1 = apriori.createC1(dataSet)\n",
        "C1"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "[frozenset({1}),\n",
              " frozenset({2}),\n",
              " frozenset({3}),\n",
              " frozenset({4}),\n",
              " frozenset({5})]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#构建集合表示的数据集D。\n",
        "D = list(map(set, dataSet))\n",
        "D"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "有了集合形式的数据，就可以去掉那些不满足最小支持度的项集。对上面这个例子，我们使用0.5 作为最小支持度水平："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "L1, suppData0 = apriori.scanD(D, C1, 0.5)\n",
        "L1"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "suppData0"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": [
              "{frozenset({1}): 0.5,\n",
              " frozenset({3}): 0.75,\n",
              " frozenset({4}): 0.25,\n",
              " frozenset({2}): 0.75,\n",
              " frozenset({5}): 0.75}"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "上述4个项集构成了L1列表，该列表中的每个单物品项集至少出现在50%以上的记录中。由于物品4并没有达到最小支持度，所以没有包含在L1中。通过去掉这件物品，减少了查找两物品项集的工作量。\n",
        "\n",
        "### 组织完整的 Apriori 算法\n",
        "\n",
        "整个Apriori算法的伪代码如下：\n",
        "\n",
        "    当集合中项的个数大于0时\n",
        "        构建一个k个项组成的候选项集的列表 \n",
        "        检查数据以确认每个项集都是频繁的 \n",
        "        保留频繁项集并构建k+1项组成的候选项集的列表\n",
        "        \n",
        "既然可以过滤集合，那么就能够构建完整的Apriori算法了"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "L, suppData = apriori.apriori(dataSet)\n",
        "L\n",
        "#L包含满足最小支持度为0.5的频繁项集列表，下面看一下具体值："
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "[[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})],\n",
              " [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})],\n",
              " [frozenset({2, 3, 5})],\n",
              " []]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(L[0],'\\n',L[1],'\\n',L[2],'\\n',L[3])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[frozenset({5}), frozenset({2}), frozenset({3}), frozenset({1})] \n",
            " [frozenset({2, 3}), frozenset({3, 5}), frozenset({2, 5}), frozenset({1, 3})] \n",
            " [frozenset({2, 3, 5})] \n",
            " []\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suppData"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": [
              "{frozenset({1}): 0.5,\n",
              " frozenset({3}): 0.75,\n",
              " frozenset({4}): 0.25,\n",
              " frozenset({2}): 0.75,\n",
              " frozenset({5}): 0.75,\n",
              " frozenset({1, 3}): 0.5,\n",
              " frozenset({2, 5}): 0.75,\n",
              " frozenset({3, 5}): 0.5,\n",
              " frozenset({2, 3}): 0.5,\n",
              " frozenset({1, 5}): 0.25,\n",
              " frozenset({1, 2}): 0.25,\n",
              " frozenset({2, 3, 5}): 0.5}"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "每个项集都是在函数apriori()中调用函数aprioriGen()来生成的。下面看一下aprioriGen() 函数的工作流程："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "apriori.aprioriGen(L[0], 2) #k = 2表示生成的元素长度为2，根据c1生成的"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": [
              "[frozenset({2, 5}),\n",
              " frozenset({3, 5}),\n",
              " frozenset({1, 5}),\n",
              " frozenset({2, 3}),\n",
              " frozenset({1, 2}),\n",
              " frozenset({1, 3})]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里的6个集合是候选项集Ck中的元素。其中4个集合在$L[1]$中，剩下2个集合被函数scanD() 过滤掉。 下面再尝试一下70%的支持度："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "L, suppData = apriori.apriori(dataSet, minSupport=0.7)\n",
        "L"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": [
              "[[frozenset({5}), frozenset({2}), frozenset({3})], [frozenset({2, 5})], []]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "变量suppData是一个字典，它包含我们项集的支持度值。现在暂时不考虑这些值，不过下 一节会用到这些值。\n",
        "\n",
        "现在可以知道哪些项出现在70%以上的记录中，还可以基于这些信息得到一些结论。我们可 以像许多程序一样利用数据得到一些结论，或者可以生成if-then形式的关联规则来理解数据。 下一节会就此展开讨论。\n",
        "\n",
        "### 从频繁项集中挖掘关联规则\n",
        "\n",
        "可以利用关联分析发现许多有趣的内容。人们最常寻找的两个目标是频繁项集与关联规则。上一节介绍如何使用Apriori算法来发现频繁项集，现在需要解决的问题是如何找出关联规则。 要找到关联规则，我们首先从一个频繁项集开始。我们知道集合中的元素是不重复的，但我们想知道基于这些元素能否获得其他内容。某个元素或者某个元素集合可能会推导出另一个元素。从杂货店的例子可以得到，如果有一个频繁项集{豆奶, 莴苣}，那么就可能有一条关联规 则“豆奶 ➞ 莴苣”。这意味着如果有人购买了豆奶，那么在统计上他会购买莴苣的概率较大。 但是,这一条反过来并不总是成立。也就是说，即使“豆奶 ➞ 莴苣”统计上显著，那么“莴苣 ➞ 豆奶”也不一定成立。（从逻辑研究上来讲，箭头左边的集合称作前件，箭头右边的集合称为后件。）\n",
        "\n",
        "11.3节给出了频繁项集的量化定义，即它满足最小支持度要求。对于关联规则，我们也有类似的量化方法，这种量化指标称为可信度。 一条规则P ➞ H的可信度定义为 support(P | H)/support(P)。记住，在Python中，操作符|表示集合的并操作，而数学上集合并的符号是 $U$ 。 P | H是指所有出现在集合P或者集合H中的元素。前面一节已经计算了所有频繁项集支持度。现在想获得可信度，所需要做的只是取出那些支持度值做一次除法运算。 从一个频繁项集中可以产生多少条关联规则？图11-4的网格图给出的是从项集{0,1,2,3}产生 的所有关联规则。为找到感兴趣的规则，我们先生成一个可能的规则列表，然后测试每条规则的 可信度。如果可信度不满足最小要求，则去掉该规则。\n",
        "\n",
        "<img src=\"pic/pic3.png\" style=\"width:400;height:400px;\">\n",
        "\n",
        "对于频繁项集{0,1,2,3}的关联规则网格示意图。阴影区域给出的是低可信度的规则。如 果发现0,1,2→3是一条低可信度规则，那么所有其他以3作为后件的规则可信度也会较低.\n",
        "\n",
        "类似于上一节的频繁项集生成，我们可以为每个频繁项集产生许多关联规则。如果能够减少规则数目来确保问题的可解性，那么计算起来就会好很多。可以观察到，如果某条规则并不满足最小可信度要求，那么该规则的**所有子集也不会满足最小可信度要求**。以图11-4为例，假设规则 0,1,2 ➞ 3并不满足最小可信度要求，那么就知道任何左部为{0,1,2}子集的规则也不会满足最小可 信度要求。在图11-4中这些规则上都加了阴影来表示。\n",
        "\n",
        "可以**利用关联规则的上述性质属性来减少需要测试的规则数目。类似于程序清单11-2中的 Apriori算法**，可以首先从一个频繁项集开始，接着创建一个规则列表，其中规则右部只包含一个元素，然后对这些规则进行测试。接下来合并所有剩余规则来创建一个新的规则列表，其中规则右部包含两个元素。这种方法也被称作分级法。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#现在生成一个最小支持度是0.5的频繁项集的集合：\n",
        "L, suppData = apriori.apriori(dataSet, minSupport=0.5)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rules = apriori.generateRules(L, suppData, minConf=0.7)\n",
        "rules\n",
        "#结果中给出三条规则：{1} ➞ {3}、{5} ➞ {2}及{2} ➞ {5}。可以看到，后两条包含2和5的规则 可以互换前件和后件，但是#前一条包含1和3 的规则不行。下面降低可信度阈值之后看一下结果："
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
            "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
            "frozenset({1}) --> frozenset({3}) conf: 1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": [
              "[(frozenset({5}), frozenset({2}), 1.0),\n",
              " (frozenset({2}), frozenset({5}), 1.0),\n",
              " (frozenset({1}), frozenset({3}), 1.0)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "rules = apriori.generateRules(L, suppData, minConf=0.5)\n",
        "rules"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frozenset({3}) --> frozenset({2}) conf: 0.6666666666666666\n",
            "frozenset({2}) --> frozenset({3}) conf: 0.6666666666666666\n",
            "frozenset({5}) --> frozenset({3}) conf: 0.6666666666666666\n",
            "frozenset({3}) --> frozenset({5}) conf: 0.6666666666666666\n",
            "frozenset({5}) --> frozenset({2}) conf: 1.0\n",
            "frozenset({2}) --> frozenset({5}) conf: 1.0\n",
            "frozenset({3}) --> frozenset({1}) conf: 0.6666666666666666\n",
            "frozenset({1}) --> frozenset({3}) conf: 1.0\n",
            "frozenset({5}) --> frozenset({2, 3}) conf: 0.6666666666666666\n",
            "frozenset({3}) --> frozenset({2, 5}) conf: 0.6666666666666666\n",
            "frozenset({2}) --> frozenset({3, 5}) conf: 0.6666666666666666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": [
              "[(frozenset({3}), frozenset({2}), 0.6666666666666666),\n",
              " (frozenset({2}), frozenset({3}), 0.6666666666666666),\n",
              " (frozenset({5}), frozenset({3}), 0.6666666666666666),\n",
              " (frozenset({3}), frozenset({5}), 0.6666666666666666),\n",
              " (frozenset({5}), frozenset({2}), 1.0),\n",
              " (frozenset({2}), frozenset({5}), 1.0),\n",
              " (frozenset({3}), frozenset({1}), 0.6666666666666666),\n",
              " (frozenset({1}), frozenset({3}), 1.0),\n",
              " (frozenset({5}), frozenset({2, 3}), 0.6666666666666666),\n",
              " (frozenset({3}), frozenset({2, 5}), 0.6666666666666666),\n",
              " (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "一旦降低可信度阈值，就可以获得更多的规则。到现在为止，我们看到上述程序能够在一个 小数据集上正常运行，\n",
        "\n",
        "## 小结\n",
        "\n",
        "关联分析是用于发现大数据集中元素间有趣关系的一个工具集，可以采用两种方式来量化这 些有趣的关系。第一种方式是使用频繁项集，它会给出经常在一起出现的元素项。第二种方式是 关联规则，每条关联规则意味着元素项之间的“如果……那么”关系。\n",
        "\n",
        "发现元素项间不同的组合是个十分耗时的任务，不可避免需要大量昂贵的计算资源，这就需 要一些更智能的方法在合理的时间范围内找到频繁项集。能够实现这一目标的一个方法是Apriori\n",
        "\n",
        "算法，它使用Apriori原理来减少在数据库上进行检查的集合的数目。Apriori原理是说如果一个元 素项是不频繁的，那么那些包含该元素的超集也是不频繁的。Apriori算法从单元素项集开始，通 过组合满足最小支持度要求的项集来形成更大的集合。支持度用来度量一个集合在原始数据中出 现的频率。\n",
        "\n",
        "关联分析可以用在许多不同物品上。商店中的商品以及网站的访问页面是其中比较常见的例 子。关联分析也曾用于查看选举人及法官的投票历史。\n",
        "\n",
        "每次增加频繁项集的大小，Apriori算法都会重新扫描整个数据集。当数据集很大时，这会显 著降低频繁项集发现的速度。下一章会介绍FP-growth算法 ，和Apriori算法相比，该算法只需要 对数据库进行两次遍历，能够显著加快发现繁项集的速度。\n",
        "\n",
        "## 关联规则生成函数没有看懂"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}